{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"# AWS Glue Studio Notebook\n",
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 1.0.7 \n",
						"Current idle_timeout is None minutes.\n",
						"idle_timeout has been set to 2880 minutes.\n",
						"Setting Glue version to: 5.0\n",
						"Previous worker type: None\n",
						"Setting new worker type to: G.8X\n",
						"Previous number of workers: None\n",
						"Setting new number of workers to: 8\n"
					]
				}
			],
			"source": [
				"%idle_timeout 2880\n",
				"%glue_version 5.0\n",
				"%worker_type G.8X\n",
				"%number_of_workers 8"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Importing neccesary library"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Trying to create a Glue session for the kernel.\n",
						"Session Type: glueetl\n",
						"Worker Type: G.8X\n",
						"Number of Workers: 8\n",
						"Idle Timeout: 2880\n",
						"Session ID: b07cc753-c701-4998-9a03-be953fc6bf9c\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 1.0.7\n",
						"--enable-glue-datacatalog true\n",
						"Waiting for session b07cc753-c701-4998-9a03-be953fc6bf9c to get into ready status...\n",
						"Session b07cc753-c701-4998-9a03-be953fc6bf9c has been created.\n",
						"\n"
					]
				}
			],
			"source": [
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"from awsglue.dynamicframe import DynamicFrame\n",
				"from pyspark.sql import SparkSession\n",
				"from pyspark.sql.functions import *\n",
				"from pyspark.sql.types import *\n",
				"from pyspark.sql.window import Window\n",
				"from pyspark.sql.types import IntegerType, DoubleType, LongType\n",
				"from pyspark.sql.functions import col, trim, mean, stddev, min, max, count, sum, expr, row_number, desc, explode\n",
				"from pyspark.sql.types import IntegerType, DoubleType, LongType\n",
				"import sys\n",
				"from datetime import datetime\n",
				"import json\n",
				"import matplotlib.pyplot as plt\n",
				"import numpy as np\n",
				"import pandas as pd"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"AWS Glue and PySpark initialized successfully!\n",
						"Spark Version: 3.5.4-amzn-0\n",
						"Glue Context: <awsglue.context.GlueContext object at 0x7f268799ec50>\n"
					]
				}
			],
			"source": [
				"## initializing spark and glue context\n",
				"from awsglue.context import GlueContext\n",
				"from pyspark.context import SparkContext\n",
				"\n",
				"def initialize_spark_context():\n",
				"    \"\"\"Initialize AWS Glue and Spark context with optimal configurations.\"\"\"\n",
				"\n",
				"    # Get existing SparkContext (do NOT create a new one)\n",
				"    sc = SparkContext.getOrCreate()\n",
				"    glueContext = GlueContext(sc)\n",
				"    spark = glueContext.spark_session\n",
				"\n",
				"    # Optional: Set Spark configurations (some may be restricted in AWS Glue)\n",
				"    spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
				"    spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
				"    \n",
				"    print(\"AWS Glue and PySpark initialized successfully!\")\n",
				"    print(f\"Spark Version: {spark.version}\")\n",
				"    print(f\"Glue Context: {glueContext}\")\n",
				"\n",
				"    return sc, glueContext, spark\n",
				"\n",
				"# Initialize contexts\n",
				"sc, glueContext, spark = initialize_spark_context()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"#  Define S3 bucket pathsfor source files needed\n",
				"bucket_name = 'yemi-data-quest'\n",
				"bls_key = 'bls/pr/pub/time.series/pr/pr.data.0.Current'\n",
				"population_key = 'API_DATA/population_data.json'"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"BLS Data loaded successfully!\n",
						"Shape: (37239, 5)\n",
						"Columns: ['series_id', 'year', 'period', 'value', 'footnote_codes']\n",
						"\n",
						"Schema:\n",
						"root\n",
						" |-- series_id: string (nullable = true)\n",
						" |-- year: integer (nullable = true)\n",
						" |-- period: string (nullable = true)\n",
						" |-- value: double (nullable = true)\n",
						" |-- footnote_codes: string (nullable = true)\n",
						"\n",
						"\n",
						"First 5 rows:\n",
						"+-----------------+----+------+-----+--------------+\n",
						"|series_id        |year|period|value|footnote_codes|\n",
						"+-----------------+----+------+-----+--------------+\n",
						"|PRS30006011      |1995|Q01   |2.6  |              |\n",
						"|PRS30006011      |1995|Q02   |2.1  |              |\n",
						"|PRS30006011      |1995|Q03   |0.9  |              |\n",
						"|PRS30006011      |1995|Q04   |0.1  |              |\n",
						"|PRS30006011      |1995|Q05   |1.4  |              |\n",
						"+-----------------+----+------+-----+--------------+\n",
						"only showing top 5 rows\n",
						"\n",
						"+-----------------+----+------+-----+--------------+\n",
						"|series_id        |year|period|value|footnote_codes|\n",
						"+-----------------+----+------+-----+--------------+\n",
						"|PRS30006011      |1995|Q01   |2.6  |              |\n",
						"|PRS30006011      |1995|Q02   |2.1  |              |\n",
						"|PRS30006011      |1995|Q03   |0.9  |              |\n",
						"|PRS30006011      |1995|Q04   |0.1  |              |\n",
						"|PRS30006011      |1995|Q05   |1.4  |              |\n",
						"+-----------------+----+------+-----+--------------+\n",
						"only showing top 5 rows\n",
						"\n",
						"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n"
					]
				}
			],
			"source": [
				"####part3-0(a) data ingestion for bls data \n",
				"def load_dynamic_frame_from_s3(glueContext, bucket_name, key, file_format=\"csv\", separator=\"\\t\", with_header=True):\n",
				"    \"\"\"Generic function to load a DynamicFrame from S3.\"\"\"\n",
				"    return glueContext.create_dynamic_frame.from_options(\n",
				"        connection_type=\"s3\",\n",
				"        connection_options={\n",
				"            \"paths\": [f\"s3://{bucket_name}/{key}\"],\n",
				"            \"recurse\": True\n",
				"        },\n",
				"        format=file_format,\n",
				"        format_options={\n",
				"            \"withHeader\": with_header,\n",
				"            \"separator\": separator\n",
				"        }\n",
				"    )\n",
				"\n",
				"def dynamic_frame_to_df(dynamic_frame):\n",
				"    \"\"\"Convert a DynamicFrame to a Spark DataFrame.\"\"\"\n",
				"    return dynamic_frame.toDF()\n",
				"\n",
				"def display_df_info(df, name=\"DataFrame\", show_rows=5):\n",
				"    \"\"\"Display information about a DataFrame.\"\"\"\n",
				"    print(f\"{name} loaded successfully!\")\n",
				"    print(f\"Shape: ({df.count()}, {len(df.columns)})\")\n",
				"    print(f\"Columns: {df.columns}\")\n",
				"    print(\"\\nSchema:\")\n",
				"    df.printSchema()\n",
				"    print(f\"\\nFirst {show_rows} rows:\")\n",
				"    df.show(show_rows, truncate=False)\n",
				"\n",
				"def load_bls_data(glueContext, bucket_name, bls_key):\n",
				"    \"\"\"Main loader for BLS data with column casting.\"\"\"\n",
				"    try:\n",
				"        dynamic_frame = load_dynamic_frame_from_s3(glueContext, bucket_name, bls_key)\n",
				"        df = dynamic_frame_to_df(dynamic_frame)\n",
				"\n",
				"        # Cast columns to correct types\n",
				"        df = df.select(\n",
				"            df[\"series_id\"].cast(\"string\"),\n",
				"            df[\"year\"].cast(\"int\"),\n",
				"            df[\"period\"].cast(\"string\"),\n",
				"            df[\"value\"].cast(\"double\"),\n",
				"            df[\"footnote_codes\"].cast(\"string\")\n",
				"        )\n",
				"\n",
				"        display_df_info(df, name=\"BLS Data\")\n",
				"        return df\n",
				"    except Exception as e:\n",
				"        print(f\"Error loading BLS data from S3: {str(e)}\")\n",
				"        raise\n",
				"\n",
				"bls_df = load_bls_data(glueContext, bucket_name, bls_key)\n",
				"bls_df.show(5, truncate=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Population Data loaded successfully!\n",
						"Shape: (10, 4)\n",
						"Columns: ['Nation ID', 'Nation', 'Year', 'Population']\n",
						"\n",
						"Schema:\n",
						"root\n",
						" |-- Nation ID: string (nullable = true)\n",
						" |-- Nation: string (nullable = true)\n",
						" |-- Year: integer (nullable = true)\n",
						" |-- Population: double (nullable = true)\n",
						"\n",
						"\n",
						"First 10 rows:\n",
						"+---------+-------------+----+------------+\n",
						"|Nation ID|Nation       |Year|Population  |\n",
						"+---------+-------------+----+------------+\n",
						"|01000US  |United States|2013|3.16128839E8|\n",
						"|01000US  |United States|2014|3.18857056E8|\n",
						"|01000US  |United States|2015|3.21418821E8|\n",
						"|01000US  |United States|2016|3.23127515E8|\n",
						"|01000US  |United States|2017|3.25719178E8|\n",
						"|01000US  |United States|2018|3.27167439E8|\n",
						"|01000US  |United States|2019|3.28239523E8|\n",
						"|01000US  |United States|2021|3.31893745E8|\n",
						"|01000US  |United States|2022|3.33287562E8|\n",
						"|01000US  |United States|2023|3.34914896E8|\n",
						"+---------+-------------+----+------------+\n",
						"\n",
						"+---------+-------------+----+------------+\n",
						"|Nation ID|Nation       |Year|Population  |\n",
						"+---------+-------------+----+------------+\n",
						"|01000US  |United States|2013|3.16128839E8|\n",
						"|01000US  |United States|2014|3.18857056E8|\n",
						"|01000US  |United States|2015|3.21418821E8|\n",
						"|01000US  |United States|2016|3.23127515E8|\n",
						"|01000US  |United States|2017|3.25719178E8|\n",
						"+---------+-------------+----+------------+\n",
						"only showing top 5 rows\n"
					]
				}
			],
			"source": [
				"## part3-0(b) data ingestion from s3 bucket\n",
				"def load_dynamic_frame_from_json(glueContext, bucket_name, key):\n",
				"    \"\"\"Load a JSON file from S3 into a DynamicFrame.\"\"\"\n",
				"    return glueContext.create_dynamic_frame.from_options(\n",
				"        connection_type=\"s3\",\n",
				"        connection_options={\n",
				"            \"paths\": [f\"s3://{bucket_name}/{key}\"],\n",
				"            \"recurse\": True\n",
				"        },\n",
				"        format=\"json\"\n",
				"    )\n",
				"\n",
				"def extract_nested_json(df, nested_field=\"data\"):\n",
				"    \"\"\"Extract data from a nested JSON column if it exists.\"\"\"\n",
				"    if nested_field in df.columns:\n",
				"        return df.select(explode(col(nested_field)).alias(\"data\")).select(\"data.*\")\n",
				"    return df\n",
				"\n",
				"def display_df_info(df, name=\"DataFrame\", show_rows=10):\n",
				"    \"\"\"Display information about a DataFrame.\"\"\"\n",
				"    print(f\"{name} loaded successfully!\")\n",
				"    print(f\"Shape: ({df.count()}, {len(df.columns)})\")\n",
				"    print(f\"Columns: {df.columns}\")\n",
				"    print(\"\\nSchema:\")\n",
				"    df.printSchema()\n",
				"    print(f\"\\nFirst {show_rows} rows:\")\n",
				"    df.show(show_rows, truncate=False)\n",
				"\n",
				"def load_population_data(glueContext, bucket_name, population_key):\n",
				"    \"\"\"Load and process population data from S3 JSON using Glue.\"\"\"\n",
				"    try:\n",
				"        dynamic_frame = load_dynamic_frame_from_json(glueContext, bucket_name, population_key)\n",
				"        df = dynamic_frame.toDF()\n",
				"        df = extract_nested_json(df, nested_field=\"data\")\n",
				"        display_df_info(df, name=\"Population Data\", show_rows=10)\n",
				"        return df\n",
				"    except Exception as e:\n",
				"        print(f\"Error loading population data: {str(e)}\")\n",
				"        raise\n",
				"population_df = load_population_data(glueContext, bucket_name, population_key)\n",
				"population_df.show(5, truncate=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Cleaning BLS data...\n",
						"Original BLS shape: (37239, 5)\n",
						"Cleaned BLS shape: (37239, 4)\n",
						"Removed 0 rows with missing values\n",
						"\n",
						"Cleaning Population data...\n",
						"Original Population shape: (10, 4)\n",
						"Cleaned Population shape: (10, 4)\n",
						"Removed 0 rows with missing values\n",
						"\n",
						"BLS Data Schema:\n",
						"root\n",
						" |-- series_id: string (nullable = true)\n",
						" |-- year: integer (nullable = true)\n",
						" |-- period: string (nullable = true)\n",
						" |-- value: double (nullable = true)\n",
						"\n",
						"\n",
						"Population Data Schema:\n",
						"root\n",
						" |-- Nation_ID: string (nullable = true)\n",
						" |-- Nation: string (nullable = true)\n",
						" |-- Year: integer (nullable = true)\n",
						" |-- Population: long (nullable = true)\n",
						"\n",
						"\n",
						"First 5 records of cleaned BLS Data:\n",
						"+-----------+----+------+-----+\n",
						"|series_id  |year|period|value|\n",
						"+-----------+----+------+-----+\n",
						"|PRS30006011|1995|Q01   |2.6  |\n",
						"|PRS30006011|1995|Q02   |2.1  |\n",
						"|PRS30006011|1995|Q03   |0.9  |\n",
						"|PRS30006011|1995|Q04   |0.1  |\n",
						"|PRS30006011|1995|Q05   |1.4  |\n",
						"+-----------+----+------+-----+\n",
						"only showing top 5 rows\n",
						"\n",
						"\n",
						"First 5 records of cleaned Population Data:\n",
						"+---------+-------------+----+----------+\n",
						"|Nation_ID|Nation       |Year|Population|\n",
						"+---------+-------------+----+----------+\n",
						"|01000US  |United States|2013|316128839 |\n",
						"|01000US  |United States|2014|318857056 |\n",
						"|01000US  |United States|2015|321418821 |\n",
						"|01000US  |United States|2016|323127515 |\n",
						"|01000US  |United States|2017|325719178 |\n",
						"+---------+-------------+----+----------+\n",
						"only showing top 5 rows\n"
					]
				}
			],
			"source": [
				"### data cleansing and transformstion to get ready for part 3-1\n",
				"def clean_bls_data(bls_df):\n",
				"    \"\"\"Clean the BLS DataFrame by trimming strings, casting types, and removing nulls.\"\"\"\n",
				"    print(\"Cleaning BLS data...\")\n",
				"    print(f\"Original BLS shape: ({bls_df.count()}, {len(bls_df.columns)})\")\n",
				"    \n",
				"    df_clean = bls_df.select(\n",
				"        trim(col(\"series_id\")).alias(\"series_id\"),\n",
				"        col(\"year\").cast(IntegerType()).alias(\"year\"),\n",
				"        trim(col(\"period\")).alias(\"period\"),\n",
				"        col(\"value\").cast(DoubleType()).alias(\"value\")\n",
				"    ).filter(\n",
				"        col(\"series_id\").isNotNull() &\n",
				"        col(\"year\").isNotNull() &\n",
				"        col(\"period\").isNotNull() &\n",
				"        col(\"value\").isNotNull()\n",
				"    )\n",
				"\n",
				"    removed_rows = bls_df.count() - df_clean.count()\n",
				"    print(f\"Cleaned BLS shape: ({df_clean.count()}, {len(df_clean.columns)})\")\n",
				"    print(f\"Removed {removed_rows} rows with missing values\")\n",
				"    df_clean.cache()\n",
				"    return df_clean\n",
				"\n",
				"def clean_population_data(population_df):\n",
				"    \"\"\"Clean the Population DataFrame by trimming strings, casting types, and removing nulls.\"\"\"\n",
				"    print(\"\\nCleaning Population data...\")\n",
				"    print(f\"Original Population shape: ({population_df.count()}, {len(population_df.columns)})\")\n",
				"    \n",
				"    df_clean = population_df.select(\n",
				"        trim(col(\"Nation ID\")).alias(\"Nation_ID\"),\n",
				"        trim(col(\"Nation\")).alias(\"Nation\"),\n",
				"        col(\"Year\").cast(IntegerType()).alias(\"Year\"),\n",
				"        col(\"Population\").cast(LongType()).alias(\"Population\")\n",
				"    ).filter(\n",
				"        col(\"Nation_ID\").isNotNull() &\n",
				"        col(\"Nation\").isNotNull() &\n",
				"        col(\"Year\").isNotNull() &\n",
				"        col(\"Population\").isNotNull()\n",
				"    )\n",
				"\n",
				"    removed_rows = population_df.count() - df_clean.count()\n",
				"    print(f\"Cleaned Population shape: ({df_clean.count()}, {len(df_clean.columns)})\")\n",
				"    print(f\"Removed {removed_rows} rows with missing values\")\n",
				"    df_clean.cache()\n",
				"    return df_clean\n",
				"\n",
				"def display_final_data(bls_df_clean, population_df_clean):\n",
				"    \"\"\"Display schema and preview of cleaned DataFrames.\"\"\"\n",
				"    print(\"\\nBLS Data Schema:\")\n",
				"    bls_df_clean.printSchema()\n",
				"    print(\"\\nPopulation Data Schema:\")\n",
				"    population_df_clean.printSchema()\n",
				"\n",
				"    print(\"\\nFirst 5 records of cleaned BLS Data:\")\n",
				"    bls_df_clean.show(5, truncate=False)\n",
				"\n",
				"    print(\"\\nFirst 5 records of cleaned Population Data:\")\n",
				"    population_df_clean.show(5, truncate=False)\n",
				"bls_df_clean = clean_bls_data(bls_df)\n",
				"population_df_clean = clean_population_data(population_df)\n",
				"display_final_data(bls_df_clean, population_df_clean)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n",
						" Population Data for Years 2013-2018:\n",
						"+----+----------+\n",
						"|Year|Population|\n",
						"+----+----------+\n",
						"|2013| 316128839|\n",
						"|2014| 318857056|\n",
						"|2015| 321418821|\n",
						"|2016| 323127515|\n",
						"|2017| 325719178|\n",
						"|2018| 327167439|\n",
						"+----+----------+\n",
						"\n",
						"\n",
						" Population Statistics:\n",
						"Mean Population: 322,069,808\n",
						"Standard Deviation: 4,158,441\n",
						"Min Population: 316,128,839\n",
						"Max Population: 327,167,439\n",
						"Count: 6\n"
					]
				}
			],
			"source": [
				"### part 3-1 generatingmean and STD logic\n",
				"def filter_population_by_year(df, start_year, end_year):\n",
				"    \"\"\"Filter population data between specified years.\"\"\"\n",
				"    filtered_df = df.filter(\n",
				"        (col(\"Year\") >= start_year) & (col(\"Year\") <= end_year)\n",
				"    )\n",
				"    print(f\"\\n Population Data for Years {start_year}-{end_year}:\")\n",
				"    filtered_df.select(\"Year\", \"Population\").orderBy(\"Year\").show()\n",
				"    return filtered_df\n",
				"\n",
				"def compute_population_statistics(df):\n",
				"    \"\"\"Compute summary statistics for population.\"\"\"\n",
				"    stats_row = df.agg(\n",
				"        mean(col(\"Population\")).alias(\"mean_population\"),\n",
				"        stddev(col(\"Population\")).alias(\"std_population\"),\n",
				"        min(col(\"Population\")).alias(\"min_population\"),\n",
				"        max(col(\"Population\")).alias(\"max_population\"),\n",
				"        count(col(\"Population\")).alias(\"count\")\n",
				"    ).collect()[0]\n",
				"    \n",
				"    stats = {\n",
				"        \"mean\": stats_row[\"mean_population\"],\n",
				"        \"std\": stats_row[\"std_population\"],\n",
				"        \"min\": stats_row[\"min_population\"],\n",
				"        \"max\": stats_row[\"max_population\"],\n",
				"        \"count\": stats_row[\"count\"]\n",
				"    }\n",
				"\n",
				"    print(f\"\\n Population Statistics:\")\n",
				"    print(f\"Mean Population: {stats['mean']:,.0f}\")\n",
				"    print(f\"Standard Deviation: {stats['std']:,.0f}\")\n",
				"    print(f\"Min Population: {stats['min']:,.0f}\")\n",
				"    print(f\"Max Population: {stats['max']:,.0f}\")\n",
				"    print(f\"Count: {stats['count']}\")\n",
				"    \n",
				"    return stats\n",
				"\n",
				"def convert_population_to_pandas(df):\n",
				"    \"\"\"Convert Spark DataFrame to pandas for visualization.\"\"\"\n",
				"    return df.select(\"Year\", \"Population\").orderBy(\"Year\").toPandas()\n",
				"# Step 1: Filter population data for 2013–2018\n",
				"population_2013_2018 = filter_population_by_year(population_df_clean, 2013, 2018)\n",
				"\n",
				"# Step 2: Compute statistics\n",
				"population_stats = compute_population_statistics(population_2013_2018)\n",
				"\n",
				"# Step 3: Prepare for visualization (if needed)\n",
				"population_data_pandas = convert_population_to_pandas(population_2013_2018)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"#optional visualization with output named poplulation_trend.png\n",
				"def plot_population_trend(population_df_pandas, mean_population):\n",
				"    \"\"\"Plot population trend and histogram using matplotlib.\"\"\"\n",
				"    plt.figure(figsize=(12, 6))\n",
				"\n",
				"    # Line chart: Population over years\n",
				"    plt.subplot(1, 2, 1)\n",
				"    plt.plot(\n",
				"        population_df_pandas['Year'],\n",
				"        population_df_pandas['Population'],\n",
				"        'bo-', linewidth=2, markersize=8\n",
				"    )\n",
				"    plt.axhline(y=mean_population, color='r', linestyle='--', alpha=0.7,\n",
				"                label=f'Mean: {mean_population:,.0f}')\n",
				"    plt.xlabel('Year')\n",
				"    plt.ylabel('Population')\n",
				"    plt.title('US Population Trend (2013–2018)')\n",
				"    plt.legend()\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    # Histogram: Population distribution\n",
				"    plt.subplot(1, 2, 2)\n",
				"    plt.hist(\n",
				"        population_df_pandas['Population'],\n",
				"        bins=6,\n",
				"        alpha=0.7,\n",
				"        color='skyblue',\n",
				"        edgecolor='black'\n",
				"    )\n",
				"    plt.axvline(x=mean_population, color='r', linestyle='--', alpha=0.7,\n",
				"                label=f'Mean: {mean_population:,.0f}')\n",
				"    plt.xlabel('Population')\n",
				"    plt.ylabel('Frequency')\n",
				"    plt.title('Population Distribution (2013–2018)')\n",
				"    plt.legend()\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    plt.tight_layout()\n",
				"    plt.show()\n",
				"\n",
				"def prepare_population_stats_dict(stats):\n",
				"    \"\"\"Prepare a dictionary of population statistics for reporting.\"\"\"\n",
				"    return {\n",
				"        'mean': stats['mean'],\n",
				"        'std': stats['std'],\n",
				"        'min': stats['min'],\n",
				"        'max': stats['max'],\n",
				"        'count': stats['count']\n",
				"    }\n",
				"# Step 4: Plot charts\n",
				"plot_population_trend(population_data_pandas, population_stats[\"mean\"])\n",
				"\n",
				"# Step 5: Prepare final stats for reporting\n",
				"population_stats_dict = prepare_population_stats_dict(population_stats)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"NameError: name 'plot_best_year_insights' is not defined\n"
					]
				}
			],
			"source": [
				"### 3-2 Best Year by Series ID\n",
				"# --- Step 1: Compute yearly totals ---\n",
				"def compute_yearly_sums(df):\n",
				"    \"\"\"Group by series_id and year, then compute total value per year.\"\"\"\n",
				"    yearly_sums = df.groupBy(\"series_id\", \"year\").agg(\n",
				"        sum(\"value\").alias(\"total_value\")\n",
				"    ).orderBy(\"series_id\", \"year\")\n",
				"    \n",
				"    print(\"Yearly Sums by Series ID (Sample):\")\n",
				"    yearly_sums.show(10)\n",
				"    \n",
				"    # Debug: Show all years for PRS30006011\n",
				"    print(\"\\nDebug: Yearly totals for PRS30006011\")\n",
				"    yearly_sums.filter(col(\"series_id\") == \"PRS30006011\").orderBy(\"year\").show(100)\n",
				"    \n",
				"    return yearly_sums\n",
				"\n",
				"# --- Step 2: Get best year per series_id ---\n",
				"def get_best_year_per_series(yearly_sums):\n",
				"    \"\"\"For each series_id, get the year with the max total_value using window function.\"\"\"\n",
				"    window_spec = Window.partitionBy(\"series_id\").orderBy(desc(\"total_value\"))\n",
				"    \n",
				"    best_years = yearly_sums.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
				"                            .filter(col(\"rank\") == 1) \\\n",
				"                            .select(\"series_id\", \"year\", \"total_value\") \\\n",
				"                            .orderBy(\"series_id\")\n",
				"    \n",
				"    print(\"\\nBest Year Report:\")\n",
				"    print(f\"Total series analyzed: {best_years.count()}\")\n",
				"    best_years.show(20)\n",
				"    \n",
				"    return best_years\n",
				"\n",
				"\n",
				"# --- Step 4: Summary statistics ---\n",
				"def summarize_best_year_stats(best_years):\n",
				"    \"\"\"Compute summary statistics from best year data using PySpark.\"\"\"\n",
				"    summary = best_years.agg(\n",
				"        count(\"*\").alias(\"total_series\"),\n",
				"        min(\"year\").alias(\"min_year\"),\n",
				"        max(\"year\").alias(\"max_year\"),\n",
				"        min(\"total_value\").alias(\"min_value\"),\n",
				"        max(\"total_value\").alias(\"max_value\"),\n",
				"        mean(\"total_value\").alias(\"mean_value\"),\n",
				"        expr(\"percentile_approx(total_value, 0.5)\").alias(\"median_value\")\n",
				"    ).collect()[0]\n",
				"\n",
				"    print(f\"\\nBest Year Report Summary:\")\n",
				"    print(f\"Total series analyzed: {summary['total_series']}\")\n",
				"    print(f\"Year range: {summary['min_year']} - {summary['max_year']}\")\n",
				"    print(f\"Value range: {summary['min_value']:.2f} - {summary['max_value']:.2f}\")\n",
				"    print(f\"Mean best year value: {summary['mean_value']:.2f}\")\n",
				"    print(f\"Median best year value: {summary['median_value']:.2f}\")\n",
				"    \n",
				"    return summary\n",
				"\n",
				"# --- Execution ---\n",
				"# Replace `bls_df_clean` with your cleaned BLS DataFrame\n",
				"yearly_sums = compute_yearly_sums(bls_df_clean)\n",
				"best_years = get_best_year_per_series(yearly_sums)\n",
				"\n",
				"# Optional: Convert to pandas for plots and export\n",
				"best_years_pandas = best_years.toPandas()\n",
				"plot_best_year_insights(best_years_pandas)\n",
				"\n",
				"# Summary\n",
				"best_year_summary = summarize_best_year_stats(best_years)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# --- Step 3: Visualize using matplotlib ---optionalllll\n",
				"def plot_best_year_insights(best_years_pandas, s3_uri):\n",
				"    \"\"\"Create a 2x2 set of matplotlib visualizations from best year data and save to S3.\"\"\"\n",
				"    fig = plt.figure(figsize=(15, 8))  # Capture the figure object\n",
				"\n",
				"    # Plot 1: Distribution of best year values\n",
				"    plt.subplot(2, 2, 1)\n",
				"    plt.hist(best_years_pandas['total_value'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
				"    plt.xlabel('Sum of Values')\n",
				"    plt.ylabel('Frequency')\n",
				"    plt.title('Distribution of Best Year Values')\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    # Plot 2: Distribution of years\n",
				"    plt.subplot(2, 2, 2)\n",
				"    year_counts = best_years_pandas['year'].value_counts().sort_index()\n",
				"    plt.bar(year_counts.index, year_counts.values, alpha=0.7, color='orange')\n",
				"    plt.xlabel('Year')\n",
				"    plt.ylabel('Number of Series')\n",
				"    plt.title('Best Years Distribution')\n",
				"    plt.xticks(rotation=45)\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    # Plot 3: Top 10 series by total_value\n",
				"    plt.subplot(2, 2, 3)\n",
				"    top_10 = best_years_pandas.nlargest(10, 'total_value')\n",
				"    plt.barh(range(len(top_10)), top_10['total_value'], alpha=0.7, color='purple')\n",
				"    plt.yticks(range(len(top_10)), top_10['series_id'])\n",
				"    plt.xlabel('Sum of Values')\n",
				"    plt.title('Top 10 Series by Best Year Value')\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    # Plot 4: Scatter of value vs year\n",
				"    plt.subplot(2, 2, 4)\n",
				"    plt.scatter(best_years_pandas['year'], best_years_pandas['total_value'], alpha=0.6, s=50)\n",
				"    plt.xlabel('Year')\n",
				"    plt.ylabel('Sum of Values')\n",
				"    plt.title('Best Year Values vs Year')\n",
				"    plt.grid(True, alpha=0.3)\n",
				"\n",
				"    plt.tight_layout()\n",
				"    save_plot_to_s3(fig, s3_uri)\n",
				"    \n",
				"    plot_best_year_insights(\n",
				"    best_years_pandas,\n",
				"    \"s3://yemi-data-quest/rearc-bls-data/best_year_insights.png\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"## 3-3 population for a given year\n",
				"def get_series_with_population(bls_df, pop_df, target_series_id, target_period):\n",
				"    \"\"\"Join filtered BLS data with population data on year.\"\"\"\n",
				"    \n",
				"    # Filter BLS data for given series_id and period\n",
				"    filtered_bls = bls_df.filter(\n",
				"        (trim(col(\"series_id\")) == target_series_id) &\n",
				"        (trim(col(\"period\")) == target_period)\n",
				"    ).select(\"series_id\", \"year\", \"period\", \"value\")\n",
				"    \n",
				"    print(\"\\nFiltered BLS Data:\")\n",
				"    filtered_bls.show()\n",
				"\n",
				"    # Trim column names in population_df (optional, for cleanliness)\n",
				"    pop_df_cleaned = pop_df.select(\n",
				"        trim(col(\"Year\")).alias(\"year\"),\n",
				"        col(\"Population\")\n",
				"    )\n",
				"\n",
				"    # Join on 'year'\n",
				"    result = filtered_bls.join(\n",
				"        pop_df_cleaned,\n",
				"        on=\"year\",\n",
				"        how=\"left\"\n",
				"    ).select(\"series_id\", \"year\", \"period\", \"value\", \"Population\")\n",
				"\n",
				"    print(\"\\nJoined BLS and Population Data:\")\n",
				"    result.show()\n",
				"\n",
				"    return result\n",
				"# Step: Generate the final report for series PRS30006032 and period Q01\n",
				"series_with_population = get_series_with_population(\n",
				"    bls_df_clean,\n",
				"    population_df_clean,\n",
				"    target_series_id=\"PRS30006032\",\n",
				"    target_period=\"Q01\"\n",
				")\n"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
